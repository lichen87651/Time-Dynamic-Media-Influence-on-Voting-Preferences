{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ec769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import one_hot_encode_columns\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3777a2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "anes_survey = 'anes_preprocessed_data.csv'\n",
    "anes_df = pd.read_csv(anes_survey, low_memory=False)\n",
    "\n",
    "anes_df = anes_df[['date', 'state', 'gender', 'race', 'age_group', 'edu', 'income', 'vote', \n",
    "                   'Yahoo', 'CNN', 'New York Times', 'Breitbart', 'Fox', 'Washington Post',\n",
    "                   'The Guardian', 'USA Today', 'BBC', 'NPR', 'Buzzfeed']]\n",
    "\n",
    "# perform one-hot encoding on the categorical column\n",
    "categorical_columns = ['state', 'gender', 'race']\n",
    "anes_df = one_hot_encode_columns(anes_df, categorical_columns)\n",
    "\n",
    "# Separate features and target\n",
    "X = anes_df.drop(['date', 'vote'], axis=1)\n",
    "y = anes_df['vote']\n",
    "\n",
    "# Step 2: Train-Test Split\n",
    "# 80% train+val, 20% test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Within train_full: 25% for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ea5dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Usage Prediction - Yahoo\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93      1151\n",
      "           1       0.08      0.01      0.02       150\n",
      "\n",
      "    accuracy                           0.87      1301\n",
      "   macro avg       0.48      0.50      0.48      1301\n",
      "weighted avg       0.79      0.87      0.83      1301\n",
      "\n",
      "News Usage Prediction - CNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      1058\n",
      "           1       0.35      0.12      0.18       243\n",
      "\n",
      "    accuracy                           0.79      1301\n",
      "   macro avg       0.58      0.53      0.53      1301\n",
      "weighted avg       0.73      0.79      0.75      1301\n",
      "\n",
      "News Usage Prediction - New York Times\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      1074\n",
      "           1       0.36      0.15      0.22       227\n",
      "\n",
      "    accuracy                           0.80      1301\n",
      "   macro avg       0.60      0.55      0.55      1301\n",
      "weighted avg       0.76      0.80      0.77      1301\n",
      "\n",
      "News Usage Prediction - Breitbart\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1269\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.97      1301\n",
      "   macro avg       0.49      0.50      0.49      1301\n",
      "weighted avg       0.95      0.97      0.96      1301\n",
      "\n",
      "News Usage Prediction - Fox\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92      1129\n",
      "           1       0.21      0.06      0.09       172\n",
      "\n",
      "    accuracy                           0.85      1301\n",
      "   macro avg       0.54      0.51      0.50      1301\n",
      "weighted avg       0.78      0.85      0.81      1301\n",
      "\n",
      "News Usage Prediction - Washington Post\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90      1099\n",
      "           1       0.33      0.10      0.16       202\n",
      "\n",
      "    accuracy                           0.83      1301\n",
      "   macro avg       0.59      0.53      0.53      1301\n",
      "weighted avg       0.77      0.83      0.79      1301\n",
      "\n",
      "News Usage Prediction - The Guardian\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      1207\n",
      "           1       0.12      0.02      0.04        94\n",
      "\n",
      "    accuracy                           0.92      1301\n",
      "   macro avg       0.53      0.50      0.50      1301\n",
      "weighted avg       0.87      0.92      0.89      1301\n",
      "\n",
      "News Usage Prediction - USA Today\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1175\n",
      "           1       0.11      0.02      0.03       126\n",
      "\n",
      "    accuracy                           0.89      1301\n",
      "   macro avg       0.50      0.50      0.49      1301\n",
      "weighted avg       0.83      0.89      0.85      1301\n",
      "\n",
      "News Usage Prediction - BBC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      1183\n",
      "           1       0.11      0.03      0.04       118\n",
      "\n",
      "    accuracy                           0.89      1301\n",
      "   macro avg       0.51      0.50      0.49      1301\n",
      "weighted avg       0.84      0.89      0.86      1301\n",
      "\n",
      "News Usage Prediction - NPR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      1151\n",
      "           1       0.17      0.05      0.08       150\n",
      "\n",
      "    accuracy                           0.86      1301\n",
      "   macro avg       0.53      0.51      0.50      1301\n",
      "weighted avg       0.80      0.86      0.83      1301\n",
      "\n",
      "News Usage Prediction - Buzzfeed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      1192\n",
      "           1       0.14      0.03      0.05       109\n",
      "\n",
      "    accuracy                           0.90      1301\n",
      "   macro avg       0.53      0.51      0.50      1301\n",
      "weighted avg       0.85      0.90      0.87      1301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Predict News Usage from Demographics (Multitarget)\n",
    "news_cols = ['Yahoo', 'CNN', 'New York Times', 'Breitbart', 'Fox', 'Washington Post',\n",
    "             'The Guardian', 'USA Today', 'BBC', 'NPR', 'Buzzfeed']\n",
    "demo_cols = [col for col in X.columns if col not in news_cols]\n",
    "\n",
    "X_demo_train = X_train[demo_cols]\n",
    "X_demo_val = X_val[demo_cols]\n",
    "X_demo_test = X_test[demo_cols]\n",
    "\n",
    "y_news_train = X_train[news_cols]\n",
    "y_news_val = X_val[news_cols]\n",
    "y_news_test = X_test[news_cols]\n",
    "\n",
    "# Use MultiOutputClassifier\n",
    "base_model = RandomForestClassifier(random_state=42)\n",
    "multi_clf = MultiOutputClassifier(base_model)\n",
    "multi_clf.fit(X_demo_train, y_news_train)\n",
    "\n",
    "# Predict on train, val, test\n",
    "predicted_news_train = pd.DataFrame(multi_clf.predict(X_demo_train), \n",
    "                                    columns=news_cols, index=X_train.index)\n",
    "predicted_news_val = pd.DataFrame(multi_clf.predict(X_demo_val), \n",
    "                                  columns=news_cols, index=X_val.index)\n",
    "predicted_news_test = pd.DataFrame(multi_clf.predict(X_demo_test), \n",
    "                                   columns=news_cols, index=X_test.index)\n",
    "\n",
    "# Optional: Evaluate per outlet\n",
    "for i, outlet in enumerate(news_cols):\n",
    "    print(f\"News Usage Prediction - {outlet}\")\n",
    "    print(classification_report(y_news_val[outlet], predicted_news_val[outlet]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed126de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.67      0.70       742\n",
      "           2       0.61      0.68      0.64       559\n",
      "\n",
      "    accuracy                           0.67      1301\n",
      "   macro avg       0.67      0.67      0.67      1301\n",
      "weighted avg       0.68      0.67      0.67      1301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Predict Vote from Demographics + Predicted News Usage\n",
    "X_vote_train = pd.concat([X_demo_train, predicted_news_train], axis=1)\n",
    "X_vote_val = pd.concat([X_demo_val, predicted_news_val], axis=1)\n",
    "X_vote_test = pd.concat([X_demo_test, predicted_news_test], axis=1)\n",
    "\n",
    "\n",
    "vote_model = load('models/news_usage_model.pkl')\n",
    "vote_model.fit(X_vote_train, y_train)\n",
    "\n",
    "# Evaluate on validation and test set\n",
    "print(\"Validation Performance:\")\n",
    "y_val_pred = vote_model.predict(X_vote_val)\n",
    "print(classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fa8e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.64      0.68       731\n",
      "           2       0.59      0.67      0.63       570\n",
      "\n",
      "    accuracy                           0.66      1301\n",
      "   macro avg       0.66      0.66      0.65      1301\n",
      "weighted avg       0.66      0.66      0.66      1301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Performance:\")\n",
    "y_test_pred = vote_model.predict(X_vote_test)\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_env",
   "language": "python",
   "name": "project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
